{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/Statics/8_1_%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_K_means.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Алгоритм K-means\n",
        "\n",
        "### Введение в K-means\n",
        "\n",
        "Алгоритм K-means — это популярный метод кластеризации, который используется для разделения набора данных на K групп (кластеры). Это один из самых простых и интуитивно понятных алгоритмов кластеризации, который находит широкое применение в различных областях, таких как маркетинг, анализ изображений, биоинформатика и многое другое.\n",
        "\n",
        "### Основная идея алгоритма\n",
        "\n",
        "Основная идея K-means заключается в минимизации внутрикластерного расстояния, то есть, в том, чтобы точки в одном кластере были как можно ближе друг к другу, а кластеры между собой — как можно дальше.\n",
        "\n",
        "### Шаги алгоритма K-means\n",
        "\n",
        "Алгоритм K-means можно описать следующими шагами:\n",
        "\n",
        "1. **Инициализация**: Выбрать K случайных точек из данных в качестве начальных центров кластеров (центроидов).\n",
        "2. **Присвоение кластеров**: Для каждой точки данных вычислить расстояние до каждого из K центроидов и присвоить точку кластеру с ближайшим центроидом.\n",
        "3. **Обновление центроидов**: Пересчитать центры кластеров, вычисляя среднее значение всех точек, принадлежащих каждому кластеру.\n",
        "4. **Проверка сходимости**: Повторять шаги 2 и 3, пока центры кластеров не перестанут изменяться (или изменятся незначительно).\n",
        "\n",
        "### Математические формулировки\n",
        "\n",
        "#### 1. Выбор начальных центроидов\n",
        "\n",
        "Пусть у нас есть набор данных, состоящий из $n$ точек $\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n$, где каждая точка $\\mathbf{x}_i \\in \\mathbb{R}^m$.\n",
        "\n",
        "Сначала мы выбираем $K$ случайных точек из данных для инициализации центроидов:\n",
        "\n",
        "$$\n",
        "C = \\{ \\mathbf{c}_1, \\mathbf{c}_2, \\ldots, \\mathbf{c}_K \\}\n",
        "$$\n",
        "\n",
        "#### 2. Присвоение кластеров\n",
        "\n",
        "Для каждой точки $\\mathbf{x}_i$ находим ближайший центроид $\\mathbf{c}_j$:\n",
        "\n",
        "$$\n",
        "\\text{cluster}(\\mathbf{x}_i) = \\arg \\min_{j} \\|\\mathbf{x}_i - \\mathbf{c}_j\\|^2\n",
        "$$\n",
        "\n",
        "где $\\|\\cdot\\|$ — это евклидова норма, определяемая как:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{x}_i - \\mathbf{c}_j\\|^2 = \\sum_{k=1}^{m} (x_{ik} - c_{jk})^2\n",
        "$$\n",
        "\n",
        "#### 3. Обновление центроидов\n",
        "\n",
        "После присвоения кластеров, обновляем центроиды:\n",
        "\n",
        "$$\n",
        "\\mathbf{c}_j = \\frac{1}{|S_j|} \\sum_{\\mathbf{x}_i \\in S_j} \\mathbf{x}_i\n",
        "$$\n",
        "\n",
        "где $S_j$ — множество точек, принадлежащих кластеру $j$, и $|S_j|$ — количество точек в кластере.\n",
        "\n",
        "#### 4. Функция стоимости\n",
        "\n",
        "Алгоритм K-means минимизирует функцию стоимости, которая измеряет внутрикластерное расстояние:\n",
        "\n",
        "$$\n",
        "J(C) = \\sum_{j=1}^{K} \\sum_{\\mathbf{x}_i \\in S_j} \\|\\mathbf{x}_i - \\mathbf{c}_j\\|^2\n",
        "$$\n",
        "\n",
        "### Пример работы алгоритма K-means\n",
        "\n",
        "Рассмотрим простой пример. Пусть у нас есть набор данных, состоящий из следующих точек:\n",
        "\n",
        "$$\n",
        "\\{(1, 2), (1, 4), (1, 0), (10, 2), (10, 4), (10, 0)\\}\n",
        "$$\n",
        "\n",
        "#### Шаг 1: Инициализация\n",
        "\n",
        "Выберем, например, $K = 2$ и инициализируем центроиды случайно:\n",
        "\n",
        "- $\\mathbf{c}_1 = (1, 2)$\n",
        "- $\\mathbf{c}_2 = (10, 2)$\n",
        "\n",
        "#### Шаг 2: Присвоение кластеров\n",
        "\n",
        "Теперь вычислим расстояния и присвоим кластеры:\n",
        "\n",
        "- Для точки $(1, 2)$:\n",
        "  - Расстояние до $\\mathbf{c}_1$: $\\sqrt{(1-1)^2 + (2-2)^2} = 0$\n",
        "  - Расстояние до $\\mathbf{c}_2$: $\\sqrt{(1-10)^2 + (2-2)^2} = 9$\n",
        "  - Присваиваем к кластеру 1.\n",
        "\n",
        "- Для точки $(1, 4)$:\n",
        "  - Расстояние до $\\mathbf{c}_1$: $\\sqrt{(1-1)^2 + (4-2)^2} = 2$\n",
        "  - Расстояние до $\\mathbf{c}_2$: $\\sqrt{(1-10)^2 + (4-2)^2} \\approx 9.2$\n",
        "  - Присваиваем к кластеру 1.\n",
        "\n",
        "- Аналогично обрабатываем остальные точки.\n",
        "\n",
        "В результате после первой итерации кластеры могут быть:\n",
        "\n",
        "- Кластер 1: $\\{(1, 2), (1, 4), (1, 0)\\}$\n",
        "- Кластер 2: $\\{(10, 2), (10, 4), (10, 0)\\}$\n",
        "\n",
        "#### Шаг 3: Обновление центроидов\n",
        "\n",
        "Теперь пересчитаем центры кластеров:\n",
        "\n",
        "- $\\mathbf{c}_1 = \\frac{1}{3} \\left((1, 2) + (1, 4) + (1, 0)\\right) = (1, \\frac{6}{3}) = (1, 2)$\n",
        "- $\\mathbf{c}_2 = \\frac{1}{3} \\left((10, 2) + (10, 4) + (10, 0)\\right) = (10, \\frac{6}{3}) = (10, 2)$\n",
        "\n",
        "#### Шаг 4: Проверка сходимости\n",
        "\n",
        "Поскольку центроиды не изменились, алгоритм завершает свою работу. В результате мы получили два кластера:\n",
        "\n",
        "- Кластер 1: $\\{(1, 2), (1, 4), (1, 0)\\}$\n",
        "- Кластер 2: $\\{(10, 2), (10, 4), (10, 0)\\}$\n",
        "\n",
        "### Преимущества и недостатки K-means\n",
        "\n",
        "#### Преимущества:\n",
        "\n",
        "- **Простота**: Легко реализовать и понимать.\n",
        "- **Эффективность**: Быстро работает на больших наборах данных.\n",
        "\n",
        "#### Недостатки:\n",
        "\n",
        "- **Неопределенность K**: Необходимо заранее знать количество кластеров $K$.\n",
        "- **Чувствительность к инициализации**: Разные начальные центроиды могут приводить к различным результатам.\n",
        "- **Предположение о форме кластеров**: K-means предполагает, что кластеры имеют сферическую форму и одинаковые размеры, что не всегда справедливо.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Давайте рассмотрим два конкретных примера использования алгоритма K-means с подробными математическими решениями.\n",
        "\n",
        "## Пример 1: Простые двумерные данные\n",
        "\n",
        "### Данные\n",
        "\n",
        "Рассмотрим набор точек:\n",
        "\n",
        "$$\n",
        "\\{(1, 2), (1, 4), (1, 0), (10, 2), (10, 4), (10, 0)\\}\n",
        "$$\n",
        "\n",
        "### Цель\n",
        "\n",
        "Мы хотим разделить эти точки на $K = 2$ кластера с использованием алгоритма K-means.\n",
        "\n",
        "### Шаг 1: Инициализация\n",
        "\n",
        "Выберем случайные центроиды. Пусть:\n",
        "\n",
        "- $\\mathbf{c}_1 = (1, 2)$\n",
        "- $\\mathbf{c}_2 = (10, 2)$\n",
        "\n",
        "### Шаг 2: Присвоение кластеров\n",
        "\n",
        "Теперь мы будем вычислять расстояние от каждой точки до центроидов и присваивать их кластерам.\n",
        "\n",
        "- Для точки $(1, 2)$:\n",
        "  - $d_{1,1} = \\sqrt{(1-1)^2 + (2-2)^2} = 0$\n",
        "  - $d_{1,2} = \\sqrt{(1-10)^2 + (2-2)^2} = 9$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(1, 4)$:\n",
        "  - $d_{2,1} = \\sqrt{(1-1)^2 + (4-2)^2} = 2$\n",
        "  - $d_{2,2} = \\sqrt{(1-10)^2 + (4-2)^2} \\approx 9.22$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(1, 0)$:\n",
        "  - $d_{3,1} = \\sqrt{(1-1)^2 + (0-2)^2} = 2$\n",
        "  - $d_{3,2} = \\sqrt{(1-10)^2 + (0-2)^2} \\approx 9.22$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(10, 2)$:\n",
        "  - $d_{4,1} = \\sqrt{(10-1)^2 + (2-2)^2} = 9$\n",
        "  - $d_{4,2} = \\sqrt{(10-10)^2 + (2-2)^2} = 0$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "- Для точки $(10, 4)$:\n",
        "  - $d_{5,1} = \\sqrt{(10-1)^2 + (4-2)^2} = \\sqrt{81 + 4} \\approx 9.05$\n",
        "  - $d_{5,2} = \\sqrt{(10-10)^2 + (4-2)^2} = 2$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "- Для точки $(10, 0)$:\n",
        "  - $d_{6,1} = \\sqrt{(10-1)^2 + (0-2)^2} = \\sqrt{81 + 4} \\approx 9.05$\n",
        "  - $d_{6,2} = \\sqrt{(10-10)^2 + (0-2)^2} = 2$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "### Итог после первого присвоения\n",
        "\n",
        "- **Кластер 1**: $\\{(1, 2), (1, 4), (1, 0)\\}$\n",
        "- **Кластер 2**: $\\{(10, 2), (10, 4), (10, 0)\\}$\n",
        "\n",
        "### Шаг 3: Обновление центроидов\n",
        "\n",
        "Теперь пересчитаем центры кластеров:\n",
        "\n",
        "- **Для кластера 1**:\n",
        "$$\n",
        "\\mathbf{c}_1 = \\left( \\frac{1 + 1 + 1}{3}, \\frac{2 + 4 + 0}{3} \\right) = \\left( 1, \\frac{6}{3} \\right) = (1, 2)\n",
        "$$\n",
        "\n",
        "- **Для кластера 2**:\n",
        "$$\n",
        "\\mathbf{c}_2 = \\left( \\frac{10 + 10 + 10}{3}, \\frac{2 + 4 + 0}{3} \\right) = \\left( 10, \\frac{6}{3} \\right) = (10, 2)\n",
        "$$\n",
        "\n",
        "### Шаг 4: Проверка сходимости\n",
        "\n",
        "Центроиды не изменились, поэтому алгоритм завершает свою работу. Итоговые кластеры:\n",
        "\n",
        "- **Кластер 1**: $\\{(1, 2), (1, 4), (1, 0)\\}$\n",
        "- **Кластер 2**: $\\{(10, 2), (10, 4), (10, 0)\\}$\n",
        "\n",
        "---\n",
        "\n",
        "## Пример 2: Более сложные данные\n",
        "\n",
        "### Данные\n",
        "\n",
        "Рассмотрим набор точек в двумерном пространстве:\n",
        "\n",
        "$$\n",
        "\\{(1, 2), (2, 3), (3, 1), (8, 7), (9, 6), (10, 8)\\}\n",
        "$$\n",
        "\n",
        "### Цель\n",
        "\n",
        "Разделить эти точки на $K = 2$ кластера.\n",
        "\n",
        "### Шаг 1: Инициализация\n",
        "\n",
        "Выберем случайные центроиды. Пусть:\n",
        "\n",
        "- $\\mathbf{c}_1 = (1, 2)$\n",
        "- $\\mathbf{c}_2 = (8, 7)$\n",
        "\n",
        "### Шаг 2: Присвоение кластеров\n",
        "\n",
        "Теперь вычислим расстояние от каждой точки до центроидов:\n",
        "\n",
        "- Для точки $(1, 2)$:\n",
        "  - $d_{1,1} = 0$\n",
        "  - $d_{1,2} = \\sqrt{(1-8)^2 + (2-7)^2} = \\sqrt{49 + 25} = \\sqrt{74} \\approx 8.6$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(2, 3)$:\n",
        "  - $d_{2,1} = \\sqrt{(2-1)^2 + (3-2)^2} = \\sqrt{1 + 1} = \\sqrt{2} \\approx 1.41$\n",
        "  - $d_{2,2} = \\sqrt{(2-8)^2 + (3-7)^2} = \\sqrt{36 + 16} = \\sqrt{52} \\approx 7.21$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(3, 1)$:\n",
        "  - $d_{3,1} = \\sqrt{(3-1)^2 + (1-2)^2} = \\sqrt{4 + 1} = \\sqrt{5} \\approx 2.24$\n",
        "  - $d_{3,2} = \\sqrt{(3-8)^2 + (1-7)^2} = \\sqrt{25 + 36} = \\sqrt{61} \\approx 7.81$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(8, 7)$:\n",
        "  - $d_{4,1} = \\sqrt{(8-1)^2 + (7-2)^2} = \\sqrt{49 + 25} = \\sqrt{74} \\approx 8.6$\n",
        "  - $d_{4,2} = 0$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "- Для точки $(9, 6)$:\n",
        "  - $d_{5,1} = \\sqrt{(9-1)^2 + (6-2)^2} = \\sqrt{64 + 16} = \\sqrt{80} \\approx 8.94$\n",
        "  - $d_{5,2} = \\sqrt{(9-8)^2 + (6-7)^2} = \\sqrt{1 + 1} = \\sqrt{2} \\approx 1.41$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "- Для точки $(10, 8)$:\n",
        "  - $d_{6,1} = \\sqrt{(10-1)^2 + (8-2)^2} = \\sqrt{81 + 36} = \\sqrt{117} \\approx 10.82$\n",
        "  - $d_{6,2} = \\sqrt{(10-8)^2 + (8-7)^2} = \\sqrt{4 + 1} = \\sqrt{5} \\approx 2.24$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "### Итог после первого присвоения\n",
        "\n",
        "- **Кластер 1**: $\\{(1, 2), (2,\n",
        "\n",
        "3), (3, 1)\\}$\n",
        "- **Кластер 2**: $\\{(8, 7), (9, 6), (10, 8)\\}$\n",
        "\n",
        "### Шаг 3: Обновление центроидов\n",
        "\n",
        "Теперь пересчитаем центры кластеров:\n",
        "\n",
        "- **Для кластера 1**:\n",
        "$$\n",
        "\\mathbf{c}_1 = \\left( \\frac{1 + 2 + 3}{3}, \\frac{2 + 3 + 1}{3} \\right) = \\left( 2, \\frac{6}{3} \\right) = (2, 2)\n",
        "$$\n",
        "\n",
        "- **Для кластера 2**:\n",
        "$$\n",
        "\\mathbf{c}_2 = \\left( \\frac{8 + 9 + 10}{3}, \\frac{7 + 6 + 8}{3} \\right) = \\left( \\frac{27}{3}, \\frac{21}{3} \\right) = (9, 7)\n",
        "$$\n",
        "\n",
        "### Шаг 4: Проверка сходимости\n",
        "\n",
        "Теперь проверим присвоение кластеров с новыми центроидами:\n",
        "\n",
        "- Для точки $(1, 2)$:\n",
        "  - $d_{1,1} = \\sqrt{(1-2)^2 + (2-2)^2} = 1$\n",
        "  - $d_{1,2} = \\sqrt{(1-9)^2 + (2-7)^2} = \\sqrt{64 + 25} = \\sqrt{89} \\approx 9.43$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(2, 3)$:\n",
        "  - $d_{2,1} = \\sqrt{(2-2)^2 + (3-2)^2} = 1$\n",
        "  - $d_{2,2} = \\sqrt{(2-9)^2 + (3-7)^2} = \\sqrt{49 + 16} = \\sqrt{65} \\approx 8.06$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(3, 1)$:\n",
        "  - $d_{3,1} = \\sqrt{(3-2)^2 + (1-2)^2} = \\sqrt{1 + 1} = \\sqrt{2} \\approx 1.41$\n",
        "  - $d_{3,2} = \\sqrt{(3-9)^2 + (1-7)^2} = \\sqrt{36 + 36} = \\sqrt{72} \\approx 8.49$\n",
        "  - **Присваиваем к кластеру 1.**\n",
        "\n",
        "- Для точки $(8, 7)$:\n",
        "  - $d_{4,1} = \\sqrt{(8-2)^2 + (7-2)^2} = \\sqrt{36 + 25} = \\sqrt{61} \\approx 7.81$\n",
        "  - $d_{4,2} = \\sqrt{(8-9)^2 + (7-7)^2} = 1$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "- Для точки $(9, 6)$:\n",
        "  - $d_{5,1} = \\sqrt{(9-2)^2 + (6-2)^2} = \\sqrt{49 + 16} = \\sqrt{65} \\approx 8.06$\n",
        "  - $d_{5,2} = \\sqrt{(9-9)^2 + (6-7)^2} = 1$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "- Для точки $(10, 8)$:\n",
        "  - $d_{6,1} = \\sqrt{(10-2)^2 + (8-2)^2} = \\sqrt{64 + 36} = \\sqrt{100} = 10$\n",
        "  - $d_{6,2} = \\sqrt{(10-9)^2 + (8-7)^2} = \\sqrt{1 + 1} = \\sqrt{2} \\approx 1.41$\n",
        "  - **Присваиваем к кластеру 2.**\n",
        "\n",
        "### Итог после второго присвоения\n",
        "\n",
        "- **Кластер 1**: $\\{(1, 2), (2, 3), (3, 1)\\}$\n",
        "- **Кластер 2**: $\\{(8, 7), (9, 6), (10, 8)\\}$\n",
        "\n",
        "### Шаг 5: Проверка сходимости\n",
        "\n",
        "Центроиды не изменились, и точки остались в тех же кластерах, что означает, что алгоритм завершил свою работу.\n",
        "\n",
        "### Заключение\n",
        "\n",
        "Мы рассмотрели два примера применения алгоритма K-means, где шаги были подробно объяснены с использованием математических формул. Эти примеры показывают, как можно разделить наборы данных на кластеры, используя K-means, и как обновляются центры кластеров на каждом этапе.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Давайте реализуем оба примера иерархической кластеризации на Python, используя библиотеки `numpy`, `pandas`, `scipy`, и `matplotlib`. Мы рассмотрим два примера: первый с простыми двумерными данными и второй с набором данных Iris.\n",
        "\n",
        "### Установка необходимых библиотек\n",
        "\n",
        "Если у вас ещё не установлены эти библиотеки, выполните команду:\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scipy matplotlib seaborn\n",
        "```\n",
        "\n",
        "### Пример 1: Простая агломеративная кластеризация\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "\n",
        "# Данные\n",
        "data = np.array([\n",
        "    [1, 2],   # A\n",
        "    [2, 3],   # B\n",
        "    [3, 3],   # C\n",
        "    [6, 5],   # D\n",
        "    [7, 8],   # E\n",
        "    [8, 8]    # F\n",
        "])\n",
        "\n",
        "# Стандартизация данных (необязательно для простого примера)\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# data = scaler.fit_transform(data)\n",
        "\n",
        "# Вычисление агломеративной кластеризации\n",
        "Z = linkage(data, method='ward')\n",
        "\n",
        "# Построение дендрограммы\n",
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(Z, labels=[f'Point {i+1}' for i in range(len(data))])\n",
        "plt.title('Dendrogram for Hierarchical Clustering')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()\n",
        "\n",
        "# Получение кластеров с порогом (например, 5)\n",
        "clusters = fcluster(Z, t=5, criterion='distance')\n",
        "print(\"Clusters:\", clusters)\n",
        "```\n",
        "\n",
        "### Пример 2: Иерархическая кластеризация на наборе данных Iris\n",
        "\n",
        "Теперь давайте применим иерархическую кластеризацию к набору данных Iris.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Загрузка данных Iris\n",
        "iris = load_iris()\n",
        "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Стандартизация данных\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Вычисление агломеративной кластеризации\n",
        "Z = linkage(data_scaled, method='ward')\n",
        "\n",
        "# Построение дендрограммы\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(Z, labels=iris.target_names[iris.target])\n",
        "plt.title('Dendrogram for Iris Dataset')\n",
        "plt.xlabel('Iris Species')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()\n",
        "\n",
        "# Получение кластеров с порогом\n",
        "clusters = fcluster(Z, t=7, criterion='distance')\n",
        "data['Cluster'] = clusters\n",
        "print(data.head())\n",
        "```\n",
        "\n",
        "### Пояснения к коду\n",
        "\n",
        "1. **Импорт библиотек**: Мы используем `numpy`, `pandas`, `scipy` и `matplotlib` для выполнения кластеризации и визуализации.\n",
        "2. **Пример 1**:\n",
        "   - Создаем массив с координатами объектов.\n",
        "   - Применяем метод `linkage` для агломеративной кластеризации с использованием метода Уорда.\n",
        "   - Строим дендрограмму с помощью функции `dendrogram`.\n",
        "   - Получаем кластеры с использованием функции `fcluster` с заданным порогом.\n",
        "3. **Пример 2**:\n",
        "   - Загружаем набор данных Iris.\n",
        "   - Стандартизируем данные.\n",
        "   - Применяем агломеративную кластеризацию и строим дендрограмму.\n",
        "   - Получаем кластеры и добавляем их к DataFrame.\n",
        "\n",
        "### Запуск кода\n",
        "\n",
        "Скопируйте каждый из примеров в отдельный Python файл или в Jupyter Notebook и выполните. Вы должны увидеть дендрограммы, а также распечатку кластеров, соответствующих объектам в обоих примерах.\n",
        "\n"
      ],
      "metadata": {
        "id": "TH6xphS1QXeg"
      }
    }
  ]
}