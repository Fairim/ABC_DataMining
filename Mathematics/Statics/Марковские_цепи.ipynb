{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpXthrqkTG4AdVX+U06w54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0/%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B5_%D1%86%D0%B5%D0%BF%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Марковские цепи\n",
        "\n",
        "#### Введение в марковские цепи\n",
        "\n",
        "Марковская цепь — это математическая модель, которая описывает систему, переходящую из одного состояния в другое. Основная идея марковских цепей заключается в том, что вероятность перехода из одного состояния в другое зависит только от текущего состояния, а не от предшествующих событий. Это свойство называется **свойством Маркова**, или **без памяти**.\n",
        "\n",
        "Формально марковская цепь — это последовательность случайных величин $X_0, X_1, X_2, \\ldots$, где $X_n$ обозначает состояние системы в момент времени $n$. Состояния могут быть дискретными или непрерывными, однако в данной лекции мы будем рассматривать дискретные марковские цепи.\n",
        "\n",
        "#### Основные определения\n",
        "\n",
        "1. **Пространство состояний** $S$ — это множество всех возможных состояний системы. Например, если система может находиться в трёх состояниях, то $S = \\{s_1, s_2, s_3\\}$.\n",
        "\n",
        "2. **Матрица переходных вероятностей** $P$ — это квадратная матрица, в которой каждый элемент $p_{ij}$ представляет собой вероятность перехода из состояния $s_i$ в состояние $s_j$. То есть:\n",
        "   $$\n",
        "   p_{ij} = P(X_{n+1} = s_j \\mid X_n = s_i).\n",
        "   $$\n",
        "   Причём для каждой строки матрицы выполняется условие нормировки:\n",
        "   $$\n",
        "   \\sum_{j} p_{ij} = 1, \\quad \\forall i.\n",
        "   $$\n",
        "\n",
        "3. **Начальное распределение** $\\pi$ — это вектор, который описывает вероятности нахождения системы в каждом из состояний в начальный момент времени. Пусть $\\pi_i = P(X_0 = s_i)$, тогда начальное распределение имеет вид:\n",
        "   $$\n",
        "   \\pi = (\\pi_1, \\pi_2, \\ldots, \\pi_n),\n",
        "   $$\n",
        "   где $\\sum_i \\pi_i = 1$.\n",
        "\n",
        "#### Основные свойства марковских цепей\n",
        "\n",
        "1. **Однородность**: Марковская цепь называется однородной, если вероятности перехода не зависят от времени, то есть $P(X_{n+1} = s_j \\mid X_n = s_i)$ одинаково для всех $n$.\n",
        "\n",
        "2. **Поглощающие состояния**: Состояние $s_i$ называется поглощающим, если из него невозможно выйти, то есть $p_{ii} = 1$ и $p_{ij} = 0$ для всех $j \\neq i$.\n",
        "\n",
        "3. **Классы эквивалентности и коммуникация**: Состояние $s_i$ сообщается с состоянием $s_j$, если существует вероятность попасть из $s_i$ в $s_j$ и наоборот.\n",
        "\n",
        "#### Пример построения марковской цепи\n",
        "\n",
        "Рассмотрим простую задачу: система может находиться в одном из трёх состояний $A$, $B$ или $C$. Пусть матрица переходных вероятностей задана как:\n",
        "\n",
        "$$\n",
        "P = \\begin{bmatrix}\n",
        "0.5 & 0.3 & 0.2 \\\\\n",
        "0.2 & 0.7 & 0.1 \\\\\n",
        "0.4 & 0.4 & 0.2 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Здесь вероятность перехода из состояния $A$ в состояние $A$ равна 0.5, из состояния $A$ в состояние $B$ — 0.3, а из состояния $A$ в состояние $C$ — 0.2. Аналогично читаются остальные элементы матрицы.\n",
        "\n",
        "#### Расчёт распределения вероятностей через $n$ шагов\n",
        "\n",
        "Для того чтобы найти вероятность того, что система будет находиться в определённом состоянии через $n$ шагов, нужно умножить начальное распределение на матрицу переходных вероятностей, возведённую в степень $n$:\n",
        "\n",
        "$$\n",
        "\\pi^{(n)} = \\pi P^n,\n",
        "$$\n",
        "\n",
        "где $\\pi^{(n)}$ — вектор вероятностей нахождения в каждом состоянии через $n$ шагов.\n",
        "\n",
        "#### Стационарное распределение\n",
        "\n",
        "Рассмотрим стационарное распределение, при котором система остаётся в одном и том же распределении вероятностей после каждого шага. Это означает, что:\n",
        "\n",
        "$$\n",
        "\\pi = \\pi P.\n",
        "$$\n",
        "\n",
        "Для нахождения стационарного распределения необходимо решить систему линейных уравнений:\n",
        "\n",
        "$$\n",
        "\\pi_i = \\sum_j \\pi_j p_{ji}, \\quad \\sum_i \\pi_i = 1.\n",
        "$$\n",
        "\n",
        "#### Примеры решения задач\n",
        "\n",
        "**Пример 1. Система обслуживания**\n",
        "\n",
        "Рассмотрим систему, в которой клиент находится в одном из трёх состояний: \"ожидание\" (состояние 1), \"обслуживание\" (состояние 2) и \"завершение\" (состояние 3). Матрица переходов:\n",
        "\n",
        "$$\n",
        "P = \\begin{bmatrix}\n",
        "0.6 & 0.3 & 0.1 \\\\\n",
        "0.4 & 0.5 & 0.1 \\\\\n",
        "0.0 & 0.0 & 1.0 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Здесь состояние 3 является поглощающим, так как $p_{33} = 1$.\n",
        "\n",
        "**Пример 2. Модель погодных условий**\n",
        "\n",
        "Предположим, что погода может быть \"солнечной\" (S), \"облачной\" (C) или \"дождливой\" (R). Матрица переходных вероятностей:\n",
        "\n",
        "$$\n",
        "P = \\begin{bmatrix}\n",
        "0.8 & 0.1 & 0.1 \\\\\n",
        "0.2 & 0.6 & 0.2 \\\\\n",
        "0.3 & 0.3 & 0.4 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Если сегодня погода солнечная, вероятность того, что завтра также будет солнечно, равна 0.8, а вероятность облачной или дождливой погоды — 0.1.\n",
        "\n",
        "#### Критерии сходимости марковских цепей\n",
        "\n",
        "Марковская цепь сходится к стационарному распределению, если она является **апериодической** и **неприводимой**.\n",
        "\n",
        "- **Апериодичность** означает, что состояние можно посетить через различные промежутки времени.\n",
        "- **Неприводимость** означает, что любое состояние можно достигнуть из любого другого состояния.\n",
        "\n",
        "#### Применение марковских цепей\n",
        "\n",
        "1. **Обслуживающие системы** (модели очередей, системы с отказами).\n",
        "2. **Финансовые модели** (модели изменения цен, кредитные риски).\n",
        "3. **Теория игр** (стратегии и оптимальные решения).\n",
        "4. **Генетика** (модели мутаций и наследования признаков).\n",
        "\n",
        "\n",
        "Рассмотрим конкретный пример применения марковских цепей на практике. Пусть у нас есть магазин, который работает в трёх режимах:\n",
        "\n",
        "1. **Низкий спрос** (Low) — состояние $S_1$.\n",
        "2. **Средний спрос** (Medium) — состояние $S_2$.\n",
        "3. **Высокий спрос** (High) — состояние $S_3$.\n",
        "\n",
        "Менеджер магазина хочет спрогнозировать, в каком состоянии будет находиться магазин через несколько дней, если известно, что в каждый день вероятность перехода из одного состояния в другое описывается следующей матрицей переходных вероятностей:\n",
        "\n",
        "$$\n",
        "P = \\begin{bmatrix}\n",
        "0.6 & 0.3 & 0.1 \\\\\n",
        "0.2 & 0.5 & 0.3 \\\\\n",
        "0.1 & 0.4 & 0.5 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Где $p_{ij}$ — вероятность перехода из состояния $S_i$ в состояние $S_j$. Например, вероятность того, что магазин останется в состоянии \"Низкий спрос\" на следующий день, равна 0.6, а вероятность перехода в состояние \"Средний спрос\" — 0.3.\n",
        "\n",
        "Допустим, что на текущий день спрос низкий, т.е. начальное распределение можно задать как $\\pi = [1, 0, 0]$, что означает, что вероятность нахождения магазина в состоянии $S_1$ равна 1.\n",
        "\n",
        "Теперь рассчитаем, как изменится распределение вероятностей через один и два дня.\n",
        "\n",
        "### Шаг 1: Расчёт распределения вероятностей через один день\n",
        "\n",
        "Чтобы найти распределение вероятностей через один шаг, нужно умножить вектор начального распределения $\\pi$ на матрицу переходных вероятностей $P$:\n",
        "\n",
        "$$\n",
        "\\pi^{(1)} = \\pi P = [1, 0, 0] \\begin{bmatrix}\n",
        "0.6 & 0.3 & 0.1 \\\\\n",
        "0.2 & 0.5 & 0.3 \\\\\n",
        "0.1 & 0.4 & 0.5 \\\\\n",
        "\\end{bmatrix} = [0.6, 0.3, 0.1].\n",
        "$$\n",
        "\n",
        "Таким образом, через один день вероятность того, что спрос будет низким, равна 0.6, средним — 0.3, а высоким — 0.1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Шаг 2: Расчёт распределения вероятностей через два дня\n",
        "\n",
        "Для нахождения распределения вероятностей через два дня, нужно умножить полученное распределение $\\pi^{(1)}$ на матрицу переходных вероятностей $P$ ещё раз:\n",
        "\n",
        "$$\n",
        "\\pi^{(2)} = \\pi^{(1)} P = [0.6, 0.3, 0.1] \\begin{bmatrix}\n",
        "0.6 & 0.3 & 0.1 \\\\\n",
        "0.2 & 0.5 & 0.3 \\\\\n",
        "0.1 & 0.4 & 0.5 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Теперь произведём вычисления для каждого элемента вектора $\\pi^{(2)}$:\n",
        "\n",
        "1. Вероятность нахождения в состоянии $S_1$ (низкий спрос):\n",
        "   $$\n",
        "   \\pi^{(2)}_1 = 0.6 \\cdot 0.6 + 0.3 \\cdot 0.2 + 0.1 \\cdot 0.1 = 0.36 + 0.06 + 0.01 = 0.43.\n",
        "   $$\n",
        "\n",
        "2. Вероятность нахождения в состоянии $S_2$ (средний спрос):\n",
        "   $$\n",
        "   \\pi^{(2)}_2 = 0.6 \\cdot 0.3 + 0.3 \\cdot 0.5 + 0.1 \\cdot 0.4 = 0.18 + 0.15 + 0.04 = 0.37.\n",
        "   $$\n",
        "\n",
        "3. Вероятность нахождения в состоянии $S_3$ (высокий спрос):\n",
        "   $$\n",
        "   \\pi^{(2)}_3 = 0.6 \\cdot 0.1 + 0.3 \\cdot 0.3 + 0.1 \\cdot 0.5 = 0.06 + 0.09 + 0.05 = 0.20.\n",
        "   $$\n",
        "\n",
        "Таким образом, через два дня распределение вероятностей будет следующим:\n",
        "$$\n",
        "\\pi^{(2)} = [0.43, 0.37, 0.20].\n",
        "$$\n",
        "\n",
        "Это означает, что через два дня вероятность того, что спрос будет низким, равна 0.43, средним — 0.37, а высоким — 0.20.\n",
        "\n",
        "### Шаг 3: Проверка стационарного распределения\n",
        "\n",
        "Теперь попробуем найти стационарное распределение, при котором система уже не меняет своё распределение вероятностей при последующих умножениях на матрицу $P$. Обозначим стационарное распределение как $\\pi = [\\pi_1, \\pi_2, \\pi_3]$, и это распределение должно удовлетворять уравнению:\n",
        "\n",
        "$$\n",
        "\\pi P = \\pi,\n",
        "$$\n",
        "\n",
        "что эквивалентно системе линейных уравнений:\n",
        "$$\n",
        "\\begin{cases}\n",
        "0.6\\pi_1 + 0.2\\pi_2 + 0.1\\pi_3 = \\pi_1, \\\\\n",
        "0.3\\pi_1 + 0.5\\pi_2 + 0.4\\pi_3 = \\pi_2, \\\\\n",
        "0.1\\pi_1 + 0.3\\pi_2 + 0.5\\pi_3 = \\pi_3.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Кроме того, выполняется условие нормировки:\n",
        "$$\n",
        "\\pi_1 + \\pi_2 + \\pi_3 = 1.\n",
        "$$\n",
        "\n",
        "Решая эту систему уравнений, можно найти значения $\\pi_1$, $\\pi_2$ и $\\pi_3$, которые будут представлять стационарное распределение вероятностей. Решение этой системы даёт нам следующее стационарное распределение:\n",
        "\n",
        "$$\n",
        "\\pi = [0.4, 0.4, 0.2].\n",
        "$$\n",
        "\n",
        "Это означает, что в долгосрочной перспективе вероятность того, что спрос будет низким, равна 0.4, средним — 0.4, а высоким — 0.2.\n",
        "\n",
        "### Выводы\n",
        "\n",
        "В данном примере мы рассмотрели шаги расчёта распределения вероятностей для марковской цепи с тремя состояниями. Сначала мы рассчитали вероятности через один и два дня, затем нашли стационарное распределение, показывающее, как система ведёт себя в долгосрочной перспективе. Этот подход может быть применён к различным задачам моделирования, включая экономические прогнозы, анализ производственных процессов и многие другие области.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Марковские цепи находят широкое применение в машинном обучении (ML) и глубоком обучении (DL). Они используются в различных задачах, таких как генерация последовательностей, моделирование временных рядов, построение вероятностных моделей и обучение с подкреплением. Давайте рассмотрим несколько конкретных примеров использования марковских цепей в ML и DL.\n",
        "\n",
        "### Пример 1: Генерация текстов с помощью цепей Маркова\n",
        "\n",
        "В машинном обучении для генерации текста можно использовать марковские цепи. Представим, что мы хотим сгенерировать текст на основе существующих данных, учитывая только текущие и предыдущие слова. Здесь каждое слово представляет собой состояние, а переходные вероятности зависят от частоты, с которой одно слово следует за другим.\n",
        "\n",
        "#### Шаги:\n",
        "\n",
        "1. **Сбор данных**: Собираем корпус текстов, который будем использовать для построения модели.\n",
        "2. **Построение марковской цепи**:\n",
        "   - Вычисляем частоты пар последовательных слов в тексте.\n",
        "   - Создаем матрицу переходных вероятностей, где вероятность перехода от одного слова к другому зависит от частоты их совместного появления.\n",
        "3. **Генерация текста**:\n",
        "   - Начинаем с начального слова и выбираем следующее слово на основе распределения вероятностей переходов.\n",
        "   - Повторяем процесс, пока не будет достигнута заданная длина текста.\n",
        "\n",
        "#### Пример:\n",
        "\n",
        "Пусть есть следующий текст: \"кошка сидит на окне. кошка смотрит на улицу. кошка спит на окне.\"\n",
        "\n",
        "Построим простую марковскую цепь для генерации новых предложений. Из текста можно выделить переходы:\n",
        "\n",
        "- \"кошка\" → \"сидит\", \"смотрит\", \"спит\".\n",
        "- \"сидит\" → \"на\".\n",
        "- \"на\" → \"окне\", \"улицу\".\n",
        "- и так далее.\n",
        "\n",
        "Используя эти переходы, можно сгенерировать текст вроде \"кошка сидит на окне\" или \"кошка спит на улице\".\n",
        "\n",
        "### Пример 2: Моделирование временных рядов с помощью скрытых марковских моделей (Hidden Markov Models, HMM)\n",
        "\n",
        "Скрытые марковские модели применяются для моделирования временных рядов, таких как финансовые данные, данные о погоде, речевые сигналы и биологические данные. HMM включают в себя \"скрытые\" состояния, которые недоступны напрямую, но могут быть оценены через наблюдаемые данные.\n",
        "\n",
        "#### Шаги:\n",
        "\n",
        "1. **Постановка задачи**: Допустим, мы хотим предсказать, будет ли рынок \"бычьим\" (растущим) или \"медвежьим\" (падающим), основываясь на исторических данных о ценах акций.\n",
        "2. **Определение состояний**: Состояния могут быть \"бычий рынок\" и \"медвежий рынок\", и они являются скрытыми, потому что их невозможно напрямую наблюдать.\n",
        "3. **Определение наблюдаемых данных**: Наблюдаемыми данными могут быть изменения цен акций за день.\n",
        "4. **Построение модели HMM**: Определяются вероятности перехода между состояниями и вероятности наблюдения данных в каждом состоянии.\n",
        "5. **Предсказание**: Используя алгоритмы Viterbi или Forward-Backward, можно определить вероятности нахождения системы в определённых состояниях в будущем.\n",
        "\n",
        "### Пример 3: Обучение с подкреплением (Reinforcement Learning) и марковские процессы принятия решений (Markov Decision Processes, MDP)\n",
        "\n",
        "Марковские процессы принятия решений (MDP) являются ключевыми элементами в обучении с подкреплением, где агент взаимодействует со средой и учится принимать оптимальные решения.\n",
        "\n",
        "#### Шаги:\n",
        "\n",
        "1. **Описание среды**: Среда определяется набором состояний, возможных действий и функцией вознаграждения, которая даёт агенту оценку полезности каждого действия.\n",
        "2. **Переходные вероятности**: В MDP задаются вероятности перехода от одного состояния к другому в зависимости от выбранного действия.\n",
        "3. **Функция вознаграждения**: Определяет, какое вознаграждение агент получает за выполнение действия.\n",
        "4. **Поиск оптимальной политики**: Алгоритмы обучения с подкреплением, такие как Q-обучение или SARSA, используют марковские цепи для вычисления оптимальной политики, то есть стратегии выбора действий, которая максимизирует суммарное вознаграждение.\n",
        "\n",
        "#### Пример:\n",
        "\n",
        "Рассмотрим задачу обучения робота навигации в лабиринте. Состояния соответствуют позициям робота в лабиринте, действия — это \"вверх\", \"вниз\", \"влево\" и \"вправо\", а функция вознаграждения даёт положительное значение, если робот находит выход, и отрицательное, если сталкивается с препятствием. Марковские цепи позволяют оценивать вероятность нахождения в определённых состояниях в зависимости от последовательности действий.\n",
        "\n",
        "### Пример 4: Прогнозирование последовательностей в глубоком обучении (RNN и LSTM)\n",
        "\n",
        "Хотя рекуррентные нейронные сети (RNN) и их расширенные версии, такие как LSTM (Long Short-Term Memory), не являются марковскими моделями в строгом смысле, они часто используют концепции, схожие с марковскими процессами. RNN и LSTM способны моделировать последовательные данные, такие как текст, временные ряды или данные о пользователях.\n",
        "\n",
        "#### Как это связано с марковскими цепями?\n",
        "\n",
        "- В RNN входы обрабатываются последовательно, и на каждом шаге текущее состояние сети зависит от предыдущего состояния. Это аналогично идее марковских цепей, где вероятность следующего состояния зависит только от текущего состояния.\n",
        "- В отличие от марковских цепей, RNN и LSTM могут \"помнить\" более длинные зависимости благодаря своим внутренним состояниям и параметрам сети.\n",
        "\n",
        "#### Пример:\n",
        "\n",
        "Предсказание следующего слова в предложении может быть реализовано с помощью LSTM. Модель получает последовательность слов и на основе их переходов предсказывает вероятности появления следующего слова. Это схоже с марковскими цепями, но с более сложным подходом к учёту предыдущих состояний.\n",
        "\n",
        "\n",
        "Давайте рассмотрим каждый из приведённых примеров с конкретными числовыми данными и решением шаг за шагом.\n",
        "\n",
        "### Пример 1: Генерация текста с помощью цепей Маркова\n",
        "\n",
        "Предположим, у нас есть текст: \"кошка сидит на окне. кошка смотрит на окно. кошка спит на окне.\" Мы хотим построить марковскую модель для генерации нового текста.\n",
        "\n",
        "#### Шаг 1: Построение матрицы переходных вероятностей\n",
        "\n",
        "1. Разобьём текст на пары последовательных слов:\n",
        "   - \"кошка сидит\", \"сидит на\", \"на окне\"\n",
        "   - \"кошка смотрит\", \"смотрит на\", \"на окно\"\n",
        "   - \"кошка спит\", \"спит на\", \"на окне\"\n",
        "\n",
        "2. Построим частотную таблицу переходов:\n",
        "   - \"кошка\" → \"сидит\" (1 раз), \"смотрит\" (1 раз), \"спит\" (1 раз)\n",
        "   - \"сидит\" → \"на\" (1 раз)\n",
        "   - \"смотрит\" → \"на\" (1 раз)\n",
        "   - \"спит\" → \"на\" (1 раз)\n",
        "   - \"на\" → \"окне\" (2 раза), \"окно\" (1 раз)\n",
        "\n",
        "3. Преобразуем эту таблицу в матрицу переходных вероятностей:\n",
        "   $$\n",
        "   P =\n",
        "   \\begin{bmatrix}\n",
        "   0 & 1/3 & 1/3 & 1/3 & 0 & 0 \\\\\n",
        "   0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
        "   0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
        "   0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
        "   0 & 0 & 0 & 0 & 0 & 2/3 \\\\\n",
        "   0 & 0 & 0 & 0 & 0 & 1/3 \\\\\n",
        "   \\end{bmatrix}\n",
        "   $$\n",
        "   Здесь строки и столбцы соответствуют словам \"кошка\", \"сидит\", \"смотрит\", \"спит\", \"на\", \"окне/окно\".\n",
        "\n",
        "#### Шаг 2: Генерация нового текста\n",
        "\n",
        "1. Начинаем с \"кошка\". С вероятностью \\(1/3\\) выбираем одно из слов: \"сидит\", \"смотрит\" или \"спит\".\n",
        "2. Пусть выпало \"сидит\". Следующее слово — \"на\".\n",
        "3. \"на\" с вероятностью \\(2/3\\) переходит в \"окне\", с вероятностью \\(1/3\\) — в \"окно\".\n",
        "\n",
        "Таким образом, один из возможных сгенерированных текстов может быть: \"кошка сидит на окне\".\n",
        "\n",
        "### Пример 2: Моделирование временных рядов с помощью скрытой марковской модели (HMM)\n",
        "\n",
        "Рассмотрим задачу предсказания погоды с двумя скрытыми состояниями: \"солнечно\" и \"дождливо\", и наблюдаемыми состояниями: \"хорошее настроение\" и \"плохое настроение\".\n",
        "\n",
        "#### Данные модели:\n",
        "\n",
        "- Начальное распределение: $\\pi = [0.8, 0.2]$, то есть вероятность, что начнётся с солнечного дня, равна 0.8, а с дождливого — 0.2.\n",
        "- Матрица переходов:\n",
        "  $$\n",
        "  A =\n",
        "  \\begin{bmatrix}\n",
        "  0.7 & 0.3 \\\\\n",
        "  0.4 & 0.6 \\\\\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  Где $A_{ij}$ — вероятность перехода от состояния $i$ к состоянию $j$.\n",
        "\n",
        "- Матрица наблюдений:\n",
        "  $$\n",
        "  B =\n",
        "  \\begin{bmatrix}\n",
        "  0.9 & 0.1 \\\\\n",
        "  0.2 & 0.8 \\\\\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  Где $B_{ij}$ — вероятность наблюдения $j$-го настроения при условии $i$-го состояния (солнечно или дождливо).\n",
        "\n",
        "#### Задача: Определить наиболее вероятную последовательность скрытых состояний для наблюдаемой последовательности \"хорошее настроение, плохое настроение\".\n",
        "\n",
        "1. **Инициализация (Алгоритм Витерби)**:\n",
        "   $$\n",
        "   \\delta_1(солнечно) = \\pi(солнечно) \\cdot B(солнечно, хорошее) = 0.8 \\cdot 0.9 = 0.72\n",
        "   $$\n",
        "   $$\n",
        "   \\delta_1(дождливо) = \\pi(дождливо) \\cdot B(дождливо, хорошее) = 0.2 \\cdot 0.2 = 0.04\n",
        "   $$\n",
        "\n",
        "2. **Рекурсия для второго наблюдения**:\n",
        "   $$\n",
        "   \\delta_2(солнечно) = \\max(0.72 \\cdot 0.7, 0.04 \\cdot 0.4) \\cdot 0.1 = 0.0504\n",
        "   $$\n",
        "   $$\n",
        "   \\delta_2(дождливо) = \\max(0.72 \\cdot 0.3, 0.04 \\cdot 0.6) \\cdot 0.8 = 0.1728\n",
        "   $$\n",
        "\n",
        "3. **Назад по цепи**:\n",
        "   Наиболее вероятная последовательность состояний: \"солнечно\", \"дождливо\".\n",
        "\n",
        "### Пример 3: Обучение с подкреплением и марковский процесс принятия решений (MDP)\n",
        "\n",
        "Задача: Робот перемещается по сетке 3x3. Цель — попасть в клетку с наградой +10, избегая клетки с наказанием -5.\n",
        "\n",
        "#### Данные:\n",
        "\n",
        "- Состояния: клетки (1,1), (1,2), ..., (3,3).\n",
        "- Действия: вверх, вниз, влево, вправо.\n",
        "- Функция вознаграждения: +10 в клетке (3,3), -5 в клетке (2,3).\n",
        "- Вероятности переходов — робот иногда \"скользит\" и попадает не туда (80% правильное направление, 10% отклонение).\n",
        "\n",
        "#### Поиск оптимальной стратегии:\n",
        "\n",
        "1. **Инициализация Q-функции**: Зададим начальные значения $Q(s, a) = 0$.\n",
        "2. **Алгоритм Q-обучения**:\n",
        "   $$\n",
        "   Q(s, a) = Q(s, a) + \\alpha (r + \\gamma \\max_{a'} Q(s', a') - Q(s, a))\n",
        "   $$\n",
        "   Где $\\alpha$ — коэффициент обучения, $\\gamma$ — коэффициент дисконтирования, $r$ — вознаграждение.\n",
        "3. **Обновление значений Q** для каждого перехода, пока значения не стабилизируются.\n",
        "\n",
        "После завершения Q-обучения робот будет следовать стратегии, которая максимизирует ожидаемое суммарное вознаграждение.\n",
        "\n",
        "### Пример 4: Прогнозирование последовательностей в RNN и LSTM\n",
        "\n",
        "Задача: Предсказать следующую температуру на основе данных за последние три дня.\n",
        "\n",
        "#### Шаги:\n",
        "\n",
        "1. **Данные**: Температуры за последние 5 дней: 22°C, 24°C, 23°C, 25°C, 24°C.\n",
        "2. **Обучение LSTM**:\n",
        "   - Вход: последовательность [22, 24, 23], [24, 23, 25], ...\n",
        "   - Выход: предсказание следующей температуры.\n",
        "3. **Обучение с использованием градиентного спуска**, минимизируя среднеквадратичную ошибку.\n",
        "4. **Предсказание**: Используем обученную модель для предсказания температуры на следующий день, скажем, она составляет 24.5°C.\n",
        "\n",
        "Таким образом, использование марковских цепей и их обобщений (например, HMM, MDP) помогает моделировать реальные задачи и находить оптимальные решения для различных проблем в ML и DL.\n"
      ],
      "metadata": {
        "id": "rvdras43Ofs_"
      }
    }
  ]
}